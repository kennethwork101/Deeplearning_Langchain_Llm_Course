import argparse
import sys

_path = "../../"


from langchain.chains import LLMChain, SimpleSequentialChain
from langchain.prompts import ChatPromptTemplate
from langchain.schema.output_parser import StrOutputParser
from kwwutils import clock, execute, get_llm, printit


@clock
@execute
def main(options):
    pass

def Options():
    parser = argparse.ArgumentParser()
    parser.add_argument('--embedding', type=str, help='embedding: chroma gpt4all huggingface', default='gpt4all')
    parser.add_argument('--llm_type', type=str, help='llm_type: chat or llm', default='llm')
    parser.add_argument('--repeatcnt', type=int, help='repeatcnt', default=1)
    parser.add_argument('--temperature', type=float, help='temperature', default=0.1)
    """
    parser.add_argument('--model', type=str, help='model')
    """
    parser.add_argument('--model', type=str, help='model', default="llama2")
    parser.add_argument('--models', nargs='+', default=[
        "codellama:7b",            
        "everythinglm:latest",     
        "falcon:latest",           
        "llama2:latest",           
        "medllama2:latest",        
        "mistral:instruct",        
        "mistrallite:latest",      
        "openchat:latest",         
        "orca-mini:latest",        
        "samantha-mistral:latest",        
        "vicuna:latest",           
        "wizardcoder:latest",
    ])
    args = vars(parser.parse_args())
    return args


if __name__ == '__main__':
    options = Options()
    main(**options)
